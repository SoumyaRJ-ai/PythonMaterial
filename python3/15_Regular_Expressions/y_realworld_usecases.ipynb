{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World UseCases of Regular Expressions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracting URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://example.com', 'http://news.example.com']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Visit my website at https://example.com or check out the latest news at http://news.example.com\"\n",
    "\n",
    "url_pattern = r\"https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+\"\n",
    "urls = re.findall(url_pattern, text)\n",
    "\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Validating Email Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def is_valid_email(email):\n",
    "    email_pattern = r\"^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}$\"\n",
    "    return re.match(email_pattern, email) is not None\n",
    "\n",
    "\n",
    "print(is_valid_email(\"john.doe@example.com\"))\n",
    "print(is_valid_email(\"invalid_email\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extracting Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#beautiful', '#friends', '#nature']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Just enjoying a #beautiful day with #friends in #nature\"\n",
    "\n",
    "hashtag_pattern = r\"#\\w+\"\n",
    "hashtags = re.findall(hashtag_pattern, text)\n",
    "\n",
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Parsing HTML Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://example.com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "html = '<a href=\"https://example.com\">Visit our website</a>'\n",
    "\n",
    "href_pattern = r'href=\"([^\"]*)\"'\n",
    "href = re.search(href_pattern, html).group(1)\n",
    "\n",
    "print(href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tokenizing Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'How', 'are', 'you', 'today', 'I', 'hope', 'everything', 'is', 'going', 'well', 'Have', 'a', 'great', 'day']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello! How are you today 06/12/2023? I hope everything is going well. Have a great day.\"\n",
    "\n",
    "word_pattern = r\"\\b(?![\\d.!?])\\w+\\b\"\n",
    "words = re.findall(word_pattern, text)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Removing Extra Whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence has extra whitespaces.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"This    sentence   has   extra   whitespaces.\"\n",
    "\n",
    "clean_text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Splitting Text into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!', ' How are you today?', ' I hope everything is going well.', ' Have a great day.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Hello! How are you today? I hope everything is going well. Have a great day.\"\n",
    "\n",
    "sentence_pattern = r\"(.*?[.!?])\"\n",
    "sentences = re.findall(sentence_pattern, text)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Extracting Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-12-2023']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"The event will take place on 06-12-2023. Don't miss it!\"\n",
    "\n",
    "date_pattern = r\"\\b\\d{2}-\\d{2}-\\d{4}\\b\"\n",
    "dates = re.findall(date_pattern, text)\n",
    "\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.  Extracting IP Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['192.168.0.1', '10.0.0.1', '172.16.0.1']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "log = \"Client IP: 192.168.0.1 - Request received from 10.0.0.1 - Server IP: 172.16.0.1\"\n",
    "\n",
    "ip_pattern = r\"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\"\n",
    "ips = re.findall(ip_pattern, log)\n",
    "\n",
    "print(ips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Finding Duplicate Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'duplicate']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"This is is a test sentence to find duplicate duplicate words.\"\n",
    "\n",
    "duplicate_pattern = r\"\\b(\\w+)\\b(?=.*\\b\\1\\b)\"\n",
    "duplicates = re.findall(duplicate_pattern, text)\n",
    "\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Removing HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to the Regex World  Enjoy the power of regex! \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "html = \"<h1>Welcome to the Regex World</h1><p>Enjoy the power of regex!</p>\"\n",
    "\n",
    "clean_text = re.sub(r\"<.*?>\", \" \", html)\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.  Extracting Quoted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life is short, enjoy every moment']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = 'She said, \"Life is short, enjoy every moment\"'\n",
    "\n",
    "quote_pattern = r'\"([^\"]*)\"'\n",
    "quotes = re.findall(quote_pattern, text)\n",
    "\n",
    "print(quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.  Extracting Time from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14:30']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"The meeting will start at 14:30. Please be on time.\"\n",
    "\n",
    "time_pattern = r\"\\b\\d{2}:\\d{2}\\b\"\n",
    "times = re.findall(time_pattern, text)\n",
    "\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Removing Non-Alphanumeric Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence includes  special characters \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"This sentence includes !@#$% special characters *&^.\"\n",
    "\n",
    "clean_text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.  Extracting Social Security Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123-45-6789']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"The SSN of John Doe is 123-45-6789.\"\n",
    "\n",
    "ssn_pattern = r\"\\d{3}-\\d{2}-\\d{4}\"\n",
    "ssns = re.findall(ssn_pattern, text)\n",
    "\n",
    "print(ssns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonmaterial-4Fyt9FjG-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
